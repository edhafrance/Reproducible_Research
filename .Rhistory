doc<-xmlTreeParse("./Documents/COURSERA/CLEANINGDATA/WEEK1/QUIZ1-QUESTION4.xml",useInternalNodes=TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
zip<-xpathSApply(rootNode,"//zipcode",xmlValue)
ziplist<-data.frame(zip)
result<-subset(ziplist,ziplist=="21231")
nrow(result)
######### QUIZ1 - Question 5 ##################
#fileURL4<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
#download.file(fileURL4,destfile="./Documents/COURSERA/CLEANINGDATA/WEEK1/QUIZ1-QUESTION5.csv",method="curl")
#DT<-fread("./Documents/COURSERA/CLEANINGDATA/WEEK1/QUIZ1-QUESTION5.csv")
source('~/QUIZ1CLEANING.R')
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
##COURSE PROJECT
library(downloader)
library(dplyr)
library(Hmisc)
#Header
Feature<-read.table("./Documents/COURSERA/CLEANING DATA/WEEK3_prime/features.txt",header=TRUE,sep="")
#Read XTRAIN
#Xtrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/train/X_train.txt",header=TRUE,sep="")
#ytrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/train/y_train.txt",header=TRUE,sep="")
#subject_train<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/train/subject_train.txt",header=TRUE,sep="")
#Read XTEST
#Xtest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/X_test.txt",header=TRUE,sep="")
#ytest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/y_test.txt",header=TRUE,sep="")
#subject_test<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/subject_test.txt",header=TRUE,sep="")
#MERGE1<-cbind(Feature,Xtest,subject_test,ytest)
#names(MERGE1)<-Feature
#MERGE2<-cbind(Feature,Xtrain,subject_train,ytrain)
#names(MERGE2)<-Feature
#MERGE3<-rbind(MERGE1,MERGE2)
#names(MERGE3)<-Feature
#MERGE4<-select(MERGE3,contains("std"), contains("mean"))
#MERGE5<-tbl_df(MERGE4)
##COURSE PROJECT
library(downloader)
library(dplyr)
library(Hmisc)
#Header
Feature<-read.table("./Documents/COURSERA/CLEANING DATA/WEEK3_prime/features.txt",header=TRUE,sep="")
#Read XTRAIN
#Xtrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/train/X_train.txt",header=TRUE,sep="")
#ytrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/train/y_train.txt",header=TRUE,sep="")
#subject_train<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/train/subject_train.txt",header=TRUE,sep="")
#Read XTEST
#Xtest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/X_test.txt",header=TRUE,sep="")
#ytest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/y_test.txt",header=TRUE,sep="")
#subject_test<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/subject_test.txt",header=TRUE,sep="")
#MERGE1<-cbind(Feature,Xtest,subject_test,ytest)
#names(MERGE1)<-Feature
#MERGE2<-cbind(Feature,Xtrain,subject_train,ytrain)
#names(MERGE2)<-Feature
#MERGE3<-rbind(MERGE1,MERGE2)
#names(MERGE3)<-Feature
#MERGE4<-select(MERGE3,contains("std"), contains("mean"))
#MERGE5<-tbl_df(MERGE4)
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
Feature<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/features.txt",header=TRUE,sep="")
dim(Feature)
head(Feature)
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
head(Feature)
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
##COURSE PROJECT
library(downloader)
library(dplyr)
library(Hmisc)
#Header
Feature<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/features.txt",header=FALSE,sep="")
Feature[,2]
#Read XTRAIN
#Xtrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/UCI HAR Dataset 5/train/X_train.txt",header=FALSE,sep="")
#ytrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/UCI HAR Dataset 5/train/y_train.txt",header=FALSE,sep="")
#subject_train<-read.table("/Users/edwardha/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/UCI HAR Dataset 5/train/subject_train.txt",header=FAKSE,sep="")
#Read XTEST
#Xtest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/X_test.txt",header=TRUE,sep="")
#ytest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/y_test.txt",header=TRUE,sep="")
#subject_test<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/subject_test.txt",header=TRUE,sep="")
#MERGE1<-cbind(Feature,Xtest,subject_test,ytest)
#names(MERGE1)<-Feature
#MERGE2<-cbind(Feature,Xtrain,subject_train,ytrain)
#names(MERGE2)<-Feature
#MERGE3<-rbind(MERGE1,MERGE2)
#names(MERGE3)<-Feature
#MERGE4<-select(MERGE3,contains("std"), contains("mean"))
#MERGE5<-tbl_df(MERGE4)
##COURSE PROJECT
library(downloader)
library(dplyr)
library(Hmisc)
#Header
Feature<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/features.txt",header=FALSE,sep="")
names(MERGEDATA)<-Feature[,2]
#Read XTRAIN
#Xtrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/UCI HAR Dataset 5/train/X_train.txt",header=FALSE,sep="")
#ytrain<-read.table("/Users/edwardha/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/UCI HAR Dataset 5/train/y_train.txt",header=FALSE,sep="")
#subject_train<-read.table("/Users/edwardha/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/UCI HAR Dataset 5/train/subject_train.txt",header=FAKSE,sep="")
#Read XTEST
#Xtest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/X_test.txt",header=TRUE,sep="")
#ytest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/y_test.txt",header=TRUE,sep="")
#subject_test<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/subject_test.txt",header=TRUE,sep="")
#MERGE1<-cbind(Feature,Xtest,subject_test,ytest)
#names(MERGE1)<-Feature
#MERGE2<-cbind(Feature,Xtrain,subject_train,ytrain)
#names(MERGE2)<-Feature
#MERGE3<-rbind(MERGE1,MERGE2)
#names(MERGE3)<-Feature
#MERGE4<-select(MERGE3,contains("std"), contains("mean"))
#MERGE5<-tbl_df(MERGE4)
names(MERGEDATA)
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
dim(Xtrain)
dim(ytrain)
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
dim(Feature)
dim(Feature$V2)
Feature$V2
Feature$V1
##COURSE PROJECT
library(downloader)
library(dplyr)
library(Hmisc)
#Header
Feature<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/features.txt",header=FALSE,sep="")
#Read XTRAIN
Xtrain<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/train/X_train.txt",header=FALSE,sep="")
ytrain<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/train/y_train.txt",header=FALSE,sep="")
subject_train<-read.table("./Documents/COURSERA/CLEANINGDATA/WEEK3_prime/train/subject_train.txt",header=FALSE,sep="")
colnames(Xtrain)<-Feature
#Read XTEST
#Xtest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/X_test.txt",header=TRUE,sep="")
#ytest<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/y_test.txt",header=TRUE,sep="")
#subject_test<-read.table("/Users/edwardha/Documents/COURSERA/CLEANING DATA/WEEK 3/UCI HAR Dataset 5/test/subject_test.txt",header=TRUE,sep="")
#MERGE1<-cbind(Feature,Xtest,subject_test,ytest)
#names(MERGE1)<-Feature
#MERGE2<-cbind(Feature,Xtrain,subject_train,ytrain)
#names(MERGE2)<-Feature
#MERGE3<-rbind(MERGE1,MERGE2)
#names(MERGE3)<-Feature
#MERGE4<-select(MERGE3,contains("std"), contains("mean"))
#MERGE5<-tbl_df(MERGE4)
head(Xtrain)
source('~/Documents/COURSERA/CLEANINGDATA/WEEK 3/run_analysis.R')
source('~/Documents/COURSERA/CLEANINGDATA/WEEK3_prime/run_analysis.R')
a##QUIZ3
library(downloader)
library(dplyr)
library(Hmisc)
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="FGDP.csv")
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="FEDSTATS_Country.csv")
# Read FGDP
FGDPRAW<-read.csv("FGDP.csv",stringsAsFactors=FALSE)
FGDP2<-FGDPRAW[5:195,]
FGDP3<-data.frame(country=FGDP2[,1],ranking=FGDP2[,2], GDP=FGDP2[,5])
# Read FEDSTAT
FEDSTATSRAW<-read.csv("FEDSTATS_Country.csv",stringsAsFactors=FALSE)
FEDSTATS2<-FEDSTATSRAW[1:235,]
FEDSTATS3<-tbl_df(FEDSTATS2)
#Merge the data
MERGEDATA<-merge(FGDP3,FEDSTATS3, by.x="country",by.y="CountryCode")
#Ranking needs to be an integer
ranking1<-as.numeric(as.character(MERGEDATA$ranking))
#Add the ranking1 into MERGEDATA
MERGEDATA1<-mutate(MERGEDATA,ranking1)
#Sort the data
Ranked<-arrange(MERGEDATA1,desc(ranking1))
#Question3
#Ranked
#names(Ranked)
#Question4
Ranked %>% group_by(Income.Group) %>% summarise(averageranking=mean(ranking1,na.rm=TRUE))
z<-cut2(Ranked$ranking1,c(38,77,115,153))
table(z,Ranked$Income.Group)
head(Ranked,n=15)
tail(Ranked,n=15)
head(Ranked)
a##QUIZ3
library(downloader)
library(dplyr)
library(Hmisc)
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="FGDP.csv")
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="FEDSTATS_Country.csv")
# Read FGDP
FGDPRAW<-read.csv("FGDP.csv",stringsAsFactors=FALSE)
FGDP2<-FGDPRAW[5:195,]
FGDP3<-data.frame(country=FGDP2[,1],ranking=FGDP2[,2], GDP=FGDP2[,5])
# Read FEDSTAT
FEDSTATSRAW<-read.csv("FEDSTATS_Country.csv",stringsAsFactors=FALSE)
FEDSTATS2<-FEDSTATSRAW[1:235,]
FEDSTATS3<-tbl_df(FEDSTATS2)
#Merge the data
MERGEDATA<-merge(FGDP3,FEDSTATS3, by.x="country",by.y="CountryCode")
#Ranking needs to be an integer
ranking1<-as.numeric(as.character(MERGEDATA$ranking))
#Add the ranking1 into MERGEDATA
MERGEDATA1<-mutate(MERGEDATA,ranking1)
#Sort the data
#Ranked<-arrange(MERGEDATA1,desc(ranking1))
#Question3
#Ranked
#names(Ranked)
#Question4
Ranked %>% group_by(Income.Group) %>% summarise(averageranking=mean(ranking1,na.rm=TRUE))
#Rank
#z<-cut2(Ranked$ranking1,c(38,77,115,153))
#table(z,Ranked$Income.Group)
a##QUIZ3
library(downloader)
library(dplyr)
library(Hmisc)
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="FGDP.csv")
download("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="FEDSTATS_Country.csv")
# Read FGDP
FGDPRAW<-read.csv("FGDP.csv",stringsAsFactors=FALSE)
FGDP2<-FGDPRAW[5:195,]
FGDP3<-data.frame(country=FGDP2[,1],ranking=FGDP2[,2], GDP=FGDP2[,5])
# Read FEDSTAT
FEDSTATSRAW<-read.csv("FEDSTATS_Country.csv",stringsAsFactors=FALSE)
FEDSTATS2<-FEDSTATSRAW[1:235,]
FEDSTATS3<-tbl_df(FEDSTATS2)
#Merge the data
MERGEDATA<-merge(FGDP3,FEDSTATS3, by.x="country",by.y="CountryCode")
#Ranking needs to be an integer
ranking1<-as.numeric(as.character(MERGEDATA$ranking))
#Add the ranking1 ilto MERGEDATA
MERGEDATA1<-mutate(MERGEDATA,ranking1)
#Sort the data
#Ranked<-arrange(MERGEDATA1,desc(ranking1))
#Question3
#Ranked
#names(Ranked)
#Question4
#Ranked %>% group_by(Income.Group) %>% summarise(averageranking=mean(ranking1,na.rm=TRUE))
#Rank
z<-cut2(Ranked$ranking1,c(38,77,115,153))
table(z,Ranked$Income.Group)
Rank
Ranked
install.packages"quantmod")
install.packages("quantmod")
install.packages("quantmod")
getsymbols("YHOO",scr="google")
getSymbols("YHOO",scr="google")
install.packages("quantmod")
> getSymbols("YHOO",src="google")
getSymbols("YHOO",src="google")
> getSymbols("YHOO",src="google")
getSymbols("YHOO",src="google")
getSymbols("YHOO",src="google")
addSMA(n = 10, on = 1, with.col = Cl, overlay = TRUE, col = "brown")
library("quantmod")
getSymbols("YHOO",src="google")
getSymbols("GOOG",src="yahoo") # from yahoo finance
barchart(YHOO)
barChart(YHOO)
getsymbols("GFMGX",scr="google")
getsymbols("YHOO",scr="google")
library(quantmod)
getsymbols("YHOO",scr="google")
library("quantmod")
getsymbols("YHOO",scr="google")
library("quantmod")
getsymbols("YHOO",scr="google")
library("quantmod")
getsymbols("YHOO",scr="google")
library("quantmod")
getsymbols("YHOO",scr="google")
install.packages("quantmod")
install.packages("quantmod")
library("quantmod")
getsymbols("YHOO",scr="google")
getSymbols("YHOO",src="google")
library("quantmod")
getsymbols("GFMFX",scr="google")
getSymbols("YHOO",src="google")
getSymbols("GFMGX",src="google")
library("quantmod")
getsymbols("GFMFX",scr="google")
getSymbols("GFMGX",src="google")
getSymbols("AAPL",src="google")
getSymbols("GFIGX",src="google")
install.packages('quantmod')
install.packages("quantmod")
getSymbols("YHOO",src="google") #
install.packages('quantmod')
getSymbols("YHOO",src="google") #
getSymbols("YHOO",src="google")
x <- runif(10000); y <- runif(10000)
png("tmp.png",5000,5000); plot(x,y)
dev.off()
x <- runif(10000); y <- runif(10000)
x <- runif(10000)
y <- runif(10000)
png("tmp.png",5000,5000)
plot(x,y)
dev.off()
x
y
plot(x,y)
png("EDHA.png",5000,5000)
plot(x,y)
dev.off()
png("EDHA.png",5000,5000)
plot(x,y)
dev.off()
x
y
png("EDHA2.png",5000,5000)
plot(x,y)
dev.off()
plot(x,y)
dev.copy(png,file="YO.png")
dev.off
dev.off()
ibrary(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
l
l
library(datasets)
library(ggplot2
library(ggplot2)
library(datasets)
library("ggplot2")
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
---
output:
---
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
### 1. Code for reading in the dataset and/or processing the data
```{r load the file,echo=TRUE}
library("dplyr")
library(ggplot2)
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
DATA<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
}
rowtot<-nrow(DATA2)
```{r load the file,echo=TRUE}
library("dplyr")
library(ggplot2)
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
```{r load the file,echo=TRUE}
html_document:
keep_md: yes
---
Course Project 1 - Reproducible Research 2016
====================================================================================
---
output:
html_document:
keep_md: yes
---
Course Project 1 - Reproducible Research 2016
====================================================================================
### 1. Code for reading in the dataset and/or processing the data
```{r load the file,echo=TRUE}
library("dplyr")
library(ggplot2)
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
---
---
output:
html_document:
keep_md: yes
---
Course Project 1 - Reproducible Research 2016
##====================================================================================
### 1. Code for reading in the dataset and/or processing the data
```{r load the file,echo=TRUE}
library("dplyr")
library(ggplot2)
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
DATA<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
DATA2<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
```
### 2 and 3. Total number of steps taken each day
```{r Mean and Median Total Number of Steps,echo=TRUE}
#Total number of steps taken per day
STEPS<-DATA%>%na.omit()%>%group_by(date)%>%summarise(TOTAL_STEPS=sum(steps),MEAN_STEPS=as.integer(mean(steps)),MEDIAN_STEPS=(median(steps)))
STEPS$TOTAL_STEPS<-as.numeric(STEPS$TOTAL_STEPS)
# 3. Mean and median number of steps taken each day
mean(STEPS$TOTAL_STEPS)
median(STEPS$TOTAL_STEPS)
```
```{r Histogram 1 of Total Number of Steps,echo=TRUE}
# 2. Histogram of the total number of steps taken each day
m<-ggplot(STEPS,aes(x=TOTAL_STEPS))
m+geom_histogram(breaks=seq(0,21200,by=2000),col="black",fill="green")
```
### 6. Code to describe and show a strategy for imputing missing data
The strategy is to replace NA with average steps using loops as shown in the code.
```{r replace missing values with mean, echo=TRUE}
# 6. Code to describe and show a strategy for imputing missing data
#Replace NA with average steps
#First loop is to average # of steps on days when there is a mix of NA and steps.
#Second loop is to average # of steps on days when there is only NA.  No average possible and therefore will assign a 0
#DATA2 are the filled-in data
rowtot<-nrow(DATA2)
for (i in 1:rowtot) {
if (is.na(DATA2$steps[i])==TRUE) {DATA2$steps[i]=STEPS[DATA2$date[i],3]}
}
for (i in 1:rowtot) {
if (is.na(DATA2$steps[i])==TRUE) {DATA2$steps[i]=0}
}
#Total number of steps taken per day
STEPS2<-DATA2%>%na.omit()%>%group_by(date)%>%summarise(TOTAL_STEPS2=sum(steps),MEAN_STEPS2=as.integer(mean(steps),MEDIAN_STEPS2=(median(steps))))
STEPS2$TOTAL_STEPS2<-as.numeric(STEPS2$TOTAL_STEPS2)
STEPS2$date<-as.Date(STEPS2$date) #Transform to date format
```
### 7. Histogram of the total number of steps taken each day after missing values are imputed
```{r histogram 2 of Total Number of Steps, echo=TRUE}
# 7. Histogram of the total number of steps taken each day with no missing values
n<-ggplot(STEPS2,aes(x=TOTAL_STEPS2))
n+geom_histogram(breaks=seq(0,21200,by=2000),col="black",fill="pink")
```
```{r Weekday or Weekend, echo=TRUE}
STEPS2$WEEKDAY<-weekdays(STEPS2$date) #Weekdays to find out if falls on Saturday or Sunday
```
The overall pattern of the histograms did not change.  The green histogram (N/A ignored) and pink histogram (average value of N/A) will have slightly different values given that the calculation is different.  But the overall pattern did not change drastically.
```{r missing values, echo=TRUE}
#Calculate the number of mssing values
MISSING_VALUES<-sum(is.na(DATA$steps))
MISSING_VALUES
```
### 4. and 5. Time series plot of the average number of steps taken
```{r Plot Average Number of Steps Taken Across All Days, echo=TRUE}
PLOT_DATA<-DATA2%>%group_by(interval)%>%summarise(MEAN_EACHINTERVAL=mean(steps))
plot(PLOT_DATA$interval,PLOT_DATA$MEAN_EACHINTERVAL,type="l",xlab="Time Interval",ylab="Average",main="Average Number Of Steps Taken Across All Days")
## 5. The 5-minute interval that, on average, contains the maximum number of steps
RESULT<-PLOT_DATA[PLOT_DATA$MEAN_EACHINTERVAL==max(PLOT_DATA$MEAN_EACHINTERVAL),]
RESULT$interval
```
The 5 min interval that, on average contains the maximum number of steps is `r RESULT$interval`
### 8. Panel plot comparing the average number of steps taken per 5-minute interval across weekdays and weekends
```{r Plot Weekday Only and Weekend Only}
#Determine if days are weekdays or weekends
weekdays1<-c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday')
STEPS2$wDAY<-factor((STEPS2$WEEKDAY %in% weekdays1), levels=c(FALSE, TRUE), labels=c('weekend', 'weekday'))
#Do the same thing for DATA3 and determine weekdays or weekends
#STEP1:  Create a DATA3
DATA3<-DATA2
#STEP2:  Transform date into a date format and add a new field that displays weekday or weekend.
DATA3$date2=as.Date(DATA3$date)
DATA3$WEEKDAY<-weekdays(DATA3$date2) #Weekdays to find out if falls on Saturday or Sunday
DATA3$wDAY<-factor((DATA3$WEEKDAY %in% weekdays1), levels=c(FALSE, TRUE), labels=c('weekend', 'weekday'))
#STEP2:  Select only weekdays
WEEKDAY<-DATA3%>%filter(wDAY=="weekday")
WEEKEND<-DATA3%>%filter(wDAY=="weekend")
#STEP3: Average weekdays
par(mfrow=c(2,1))
PLOT_WEEKEND<-WEEKEND%>%group_by(interval)%>%summarise(MEAN_EACHINTERVAL1=mean(steps))
plot(PLOT_WEEKEND$interval,PLOT_WEEKEND$MEAN_EACHINTERVAL1,type="l",xlab="Time Interval",ylab="Average",main="Average Number Of Steps Taken During The Weekend")
PLOT_WEEKDAY<-WEEKDAY%>%group_by(interval)%>%summarise(MEAN_EACHINTERVAL2=mean(steps))
plot(PLOT_WEEKDAY$interval,PLOT_WEEKDAY$MEAN_EACHINTERVAL2,type="l",xlab="Time Interval",ylab="Average",main="Average Number Of Steps Taken During The Weekday")
```
##The end
library("dplyr")
library(ggplot2)
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
DATA<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
DATA2<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
STEPS<-DATA%>%na.omit()%>%group_by(date)%>%summarise(TOTAL_STEPS=sum(steps),MEAN_STEPS=as.integer(mean(steps)),MEDIAN_STEPS=(median(steps)))
library("dplyr")
library(ggplot2)
setwd("/Users/edwardha/Documents/COURSERA/Reproducible_Research")
DATA<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
DATA2<-read.csv("activity.csv", header=TRUE,sep=",", na.strings="NA")
#Total number of steps taken per day
STEPS<-DATA%>%na.omit()%>%group_by(date)%>%summarise(TOTAL_STEPS=sum(steps),MEAN_STEPS=as.integer(mean(steps)),MEDIAN_STEPS=(median(steps)))
STEPS$TOTAL_STEPS<-as.numeric(STEPS$TOTAL_STEPS)
# 3. Mean and median number of steps taken each day
mean(STEPS$TOTAL_STEPS)
median(STEPS$TOTAL_STEPS)
# 6. Code to describe and show a strategy for imputing missing data
#Replace NA with average steps
#First loop is to average # of steps on days when there is a mix of NA and steps.
#Second loop is to average # of steps on days when there is only NA.  No average possible and therefore will assign a 0
#DATA2 are the filled-in data
rowtot<-nrow(DATA2)
for (i in 1:rowtot) {
if (is.na(DATA2$steps[i])==TRUE) {DATA2$steps[i]=STEPS[DATA2$date[i],3]}
}
for (i in 1:rowtot) {
if (is.na(DATA2$steps[i])==TRUE) {DATA2$steps[i]=0}
}
#Total number of steps taken per day
STEPS2<-DATA2%>%na.omit()%>%group_by(date)%>%summarise(TOTAL_STEPS2=sum(steps),MEAN_STEPS2=as.integer(mean(steps),MEDIAN_STEPS2=(median(steps))))
STEPS2$TOTAL_STEPS2<-as.numeric(STEPS2$TOTAL_STEPS2)
STEPS2$date<-as.Date(STEPS2$date) #Transform to date format
